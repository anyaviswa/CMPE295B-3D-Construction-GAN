{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Latent-vector-representation.ipynb","provenance":[],"authorship_tag":"ABX9TyNOTLasTUDnVhLr3kKSq9Lu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Xqo-U-5xY7c","executionInfo":{"status":"ok","timestamp":1618964694543,"user_tz":420,"elapsed":300,"user":{"displayName":"Saranya Visvanathan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GignN2P2UQnVy8XQsnTNNdqC_a1UsFfj5d26NNmdg=s64","userId":"08087212822077367980"}},"outputId":"3eb228ee-d898-4964-b061-e36fd7c22221"},"source":["#Github: https://github.com/NVlabs/stylegan2-ada-pytorch\n","!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'stylegan2-ada-pytorch' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHWkx7BMxeI_","executionInfo":{"status":"ok","timestamp":1618964698469,"user_tz":420,"elapsed":606,"user":{"displayName":"Saranya Visvanathan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GignN2P2UQnVy8XQsnTNNdqC_a1UsFfj5d26NNmdg=s64","userId":"08087212822077367980"}},"outputId":"6be25a0e-69af-49de-8eb4-2fcb8af1afe7"},"source":["import torch\n","print(torch.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.8.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LL211ouzGRR","executionInfo":{"status":"ok","timestamp":1618964700068,"user_tz":420,"elapsed":337,"user":{"displayName":"Saranya Visvanathan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GignN2P2UQnVy8XQsnTNNdqC_a1UsFfj5d26NNmdg=s64","userId":"08087212822077367980"}},"outputId":"386a8aef-d343-4544-dd2d-7b14cd2d48dd"},"source":["cd stylegan2-ada-pytorch/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/stylegan2-ada-pytorch\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WG21CuD0NJjp"},"source":["## pytorch_stylegan_encoder"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNn8sWRVzDol","executionInfo":{"status":"ok","timestamp":1618971491974,"user_tz":420,"elapsed":5186,"user":{"displayName":"Saranya Visvanathan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GignN2P2UQnVy8XQsnTNNdqC_a1UsFfj5d26NNmdg=s64","userId":"08087212822077367980"}},"outputId":"6fdac3d7-9fa0-4d96-bd63-fb270802244e"},"source":["#Github: https://github.com/jacobhallberg/pytorch_stylegan_encoder\n","!git clone https://github.com/jacobhallberg/pytorch_stylegan_encoder.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'pytorch_stylegan_encoder'...\n","remote: Enumerating objects: 358, done.\u001b[K\n","remote: Total 358 (delta 0), reused 0 (delta 0), pack-reused 358\u001b[K\n","Receiving objects: 100% (358/358), 56.88 MiB | 32.50 MiB/s, done.\n","Resolving deltas: 100% (185/185), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7CTSO6f24d4","executionInfo":{"status":"ok","timestamp":1618971523120,"user_tz":420,"elapsed":333,"user":{"displayName":"Saranya Visvanathan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GignN2P2UQnVy8XQsnTNNdqC_a1UsFfj5d26NNmdg=s64","userId":"08087212822077367980"}},"outputId":"6e5ce38e-8a08-43a4-9dc4-e45a4cd51deb"},"source":["cd pytorch_stylegan_encoder/"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/pytorch_stylegan_encoder\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8b-to7R1J57","executionInfo":{"status":"ok","timestamp":1618971526431,"user_tz":420,"elapsed":2001,"user":{"displayName":"Saranya Visvanathan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GignN2P2UQnVy8XQsnTNNdqC_a1UsFfj5d26NNmdg=s64","userId":"08087212822077367980"}},"outputId":"468d3d4f-fe5f-457e-8541-5821a1a2ca0a"},"source":["!git submodule update --init --recursive"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Submodule 'InterFaceGAN' (git://github.com/ShenYujun/InterFaceGAN.git) registered for path 'InterFaceGAN'\n","Cloning into '/content/pytorch_stylegan_encoder/InterFaceGAN'...\n","Submodule path 'InterFaceGAN': checked out 'b707e942187f464251f855c92f7009b8cf13bf03'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GwUfpJF_1rEM","executionInfo":{"status":"ok","timestamp":1618971714697,"user_tz":420,"elapsed":158549,"user":{"displayName":"Saranya Visvanathan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GignN2P2UQnVy8XQsnTNNdqC_a1UsFfj5d26NNmdg=s64","userId":"08087212822077367980"}},"outputId":"d78e0ee3-bb10-44f3-d51e-71b42b1422a4"},"source":["!python encode_image.py aligned_image.jpeg dlatents.npy --save_optimized_image true"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Optimizing Latents.\n","[2021-04-21 02:19:16,219][WARNING] No pre-trained model will be loaded!\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100% 528M/528M [00:16<00:00, 32.8MB/s]\n","Step: 999, Loss: 7.040213584899902: 100% 1000/1000 [02:07<00:00,  7.86it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9B7L6rcw4RtN","executionInfo":{"status":"ok","timestamp":1618971731695,"user_tz":420,"elapsed":7534,"user":{"displayName":"Saranya Visvanathan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GignN2P2UQnVy8XQsnTNNdqC_a1UsFfj5d26NNmdg=s64","userId":"08087212822077367980"}}},"source":["#torch.save(tensor, 'file.pt') and torch.load('file.pt')\n","#TODO: Convert .npy to tensor, save tensor as .pt\n","\n","#numpy to tensor: https://aiworkbox.com/lessons/convert-a-numpy-array-to-a-pytorch-tensor\n","#tensor to .pt  https://discuss.pytorch.org/t/save-a-tensor-to-file/37136\n","\n","import tensorflow as tf\n","import numpy as np\n","import torch as torch\n","data = np.load('dlatents.npy')\n","torch.save(tf.convert_to_tensor(data),\"01Latent.pt\")"],"execution_count":8,"outputs":[]}]}